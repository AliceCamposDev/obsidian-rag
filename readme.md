# Obsidian-RAG: Your AI Assistant for Local Notes

**Transform your Obsidian vault into a conversational knowledge base.** This project allows you to ask natural language questions about your notes' content, receiving precise answers generated by a local LLM model without sending your private data to the cloud.

[![Python](https://img.shields.io/badge/Python-3.13%2B-blue)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-AGPL_v3-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Active_Development-yellow)](https://github.com/AliceCamposDev/obsidian-rag)

## Overview

Obsidian-RAG (Retrieval-Augmented Generation) is a Python application that indexes your Obsidian notes, allowing you to query them through an intelligent chatbot. The system finds the most relevant information in your notes and uses a local language model (via Ollama) to synthesize a contextual response.

**Key advantages:**
* **Complete Privacy**: Everything runs on your machine. Your notes never leave your computer.
* **Contextual Accuracy**: Responses are grounded directly in your vault's content, reducing hallucinations.
* **Full Control**: Adjust the model, search parameters, and generation settings to suit your needs.

## ðŸš€ Current POC Features

* **Automatic Indexing**: Automatically processes Markdown (`.md`) files from your Obsidian vault.
* **Semantic Search**: Finds relevant note snippets for your question using vector embeddings.
* **Context-Based Responses**: Generates answers using only retrieved context, minimizing the model's internal knowledge usage.
* **Flexible Configuration**: Adjust details like LLM models, chunk sizes, and generation parameters via `config.yaml`.
* **Command Line Interface (CLI)**: Simple, straightforward interface to interact with your knowledge.

## ðŸ“š Docs

### **Product & Planning**
- [Product Requirements (PRD)](docs/Product%20Requirements%20Document%20PRD.md) - Complete specification

<!-- 
## ðŸ“¦ Quick Installation and Setup

    Better wait for a stable version first mayb

**TODO**:
- batch processing by note
- make the readme file
- config type checking (i just wanted python to have strong static typing :sob: )
- logging
- second search with small chunks (vector_DB)
- treat hallucinations, model censures, bad answers
- list used and best matches files
- smarter search considering obsidian links between files
- UI
- optimizations (my computer is very slow)
- auto summarize for large files like entire books
- auto update embedding based on changed files
- better handling code snippets
- smart answer for technical terms and cheat sheets
- handle images and other files
- language settings
- documentation -->


<!-- ollama serve -->